{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8467825c",
   "metadata": {},
   "source": [
    "# 🚀 InnovAIte – Colab Notebook\n",
    "\n",
    "This notebook demonstrates the AI-powered content generation workflow using **LLaMA 2** for text generation and **Stable Diffusion** for image creation.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 Setup & Installations\n",
    "\n",
    "Install the required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "YxtMgKJs21dR",
    "outputId": "95d921c7-8191-462d-834e-b72f429609bc"
   },
   "outputs": [],
   "source": [
    "# Install essential libraries\n",
    "!pip install diffusers transformers torch accelerate safetensors \\\n",
    "streamlit sentencepiece python-docx bitsandbytes --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNrqMfLz3Gn4",
    "outputId": "4fb1f46f-f0e4-484a-a191-fc721fdfee7b"
   },
   "outputs": [],
   "source": [
    "!pip install python-docx\n",
    "!pip install bitsandbytes\n",
    "!pip install --upgrade bitsandbytes\n",
    "!pip install accelerate transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sqZiQmbl22dK"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "login(\"your_token_here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYtz0HbQ38nP",
    "outputId": "94543a98-e692-4454-d47f-a365601fbbfb"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from docx import Document\n",
    "from docx.shared import Inches  # Added for proper image scaling\n",
    "\n",
    "# Page Configurations (Must be the first Streamlit command)\n",
    "st.set_page_config(page_title=\"AI-Powered Prompt Studio\", layout=\"wide\", initial_sidebar_state=\"expanded\")\n",
    "\n",
    "# model names\n",
    "TEXT_MODEL = \"meta-llama/Llama-2-13b-chat-hf\"  # Upgraded model for better quality\n",
    "IMAGE_MODEL = \"stabilityai/stable-diffusion-2-1\"  # Higher quality image model\n",
    "\n",
    "# Load text generation model with 4-bit quantization\n",
    "@st.cache_resource\n",
    "def load_text_model():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=True\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        TEXT_MODEL,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"balanced\"\n",
    "    )\n",
    "    return model, tokenizer\n",
    "\n",
    "# Load image generation model\n",
    "@st.cache_resource\n",
    "def load_image_model():\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        IMAGE_MODEL,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"balanced\"\n",
    "    )\n",
    "    return pipe\n",
    "\n",
    "# Load models\n",
    "model, tokenizer = load_text_model()\n",
    "pipe = load_image_model()\n",
    "\n",
    "# Sidebar for Navigation\n",
    "st.sidebar.title(\"Navigation\")\n",
    "pages = [\"Home\", \"Prompt Optimization\", \"Text Generation\", \"Image Generation\"]\n",
    "selected_page = st.sidebar.radio(\"Go to\", pages)\n",
    "\n",
    "if selected_page == \"Home\":\n",
    "    st.title(\"Welcome to InnovAIte\")\n",
    "    st.markdown(\"### AI-Powered Blog & Image Generation\")\n",
    "    st.markdown(\"\"\"\n",
    "**Why Use InnovAIte?**\n",
    "- Generate high-quality blogs in seconds.\n",
    "- Create stunning AI-generated images.\n",
    "- Save time with automated content creation.\n",
    "- Download ready-to-use content effortlessly.\n",
    "\n",
    "**How It Works:**\n",
    "1. **Enter a topic or idea**\n",
    "2. **Generate optimized text**\n",
    "3. **Generate relevant images**\n",
    "4. **Download your content**\n",
    "\n",
    "Explore the platform using the navigation sidebar to get started!\n",
    "    \"\"\")\n",
    "\n",
    "elif selected_page == \"Prompt Optimization\":\n",
    "    st.title(\"Prompt Optimization\")\n",
    "    st.markdown(\"Refine your prompts for both text and image generation.\")\n",
    "\n",
    "    # Text Prompt Optimization\n",
    "    st.markdown(\"### Blog Input Fields\")\n",
    "    user_topic = st.text_input(\"Enter your blog topic:\", placeholder=\"E.g., Artificial Intelligence, Mental Health, Food Trends\")\n",
    "    tone = st.selectbox(\"Select the tone:\", [\"Formal\", \"Informal\", \"Creative\", \"Persuasive\", \"Inspirational\"])\n",
    "    audience = st.selectbox(\"Select the target audience:\", [\"Students\", \"Professionals\", \"General Audience\", \"Experts\"])\n",
    "    temperature = st.slider(\"Creativity Level (Temperature)\", 0.1, 1.0, 0.7)\n",
    "    response_length = st.selectbox(\"Response Length\", [\"Short (300–500 words)\", \"Medium (500–1000 words)\", \"Long (1000+ words)\"])\n",
    "    writing_style = st.selectbox(\"Writing Style\", [\"Storytelling\", \"Analytical\", \"Journalistic\", \"Technical\", \"Conversational\"])\n",
    "\n",
    "    if user_topic:\n",
    "        text_prompt = f\"Write a {tone} blog post about {user_topic} for {audience}. Creativity Level: {temperature}, Response Length: {response_length}, Writing Style: {writing_style}.\"\n",
    "        st.write(\"### Generated Text Prompt:\")\n",
    "        st.code(text_prompt)\n",
    "\n",
    "    # Image Prompt Optimization\n",
    "    st.markdown(\"### Image Input Fields\")\n",
    "    image_subject = st.text_input(\"Describe the image subject:\", placeholder=\"E.g., A futuristic cityscape, A serene mountain lake\")\n",
    "    image_style = st.selectbox(\"Select the image style:\", [\"Photorealistic\", \"Digital Art\", \"Watercolor\", \"Sketch\", \"Oil Painting\"])\n",
    "    lighting = st.selectbox(\"Lighting Conditions:\", [\"Natural\", \"Soft\", \"Dramatic\", \"Neon-lit\", \"Cinematic\", \"Sunset\", \"Nighttime\"])\n",
    "    camera_angle = st.selectbox(\"Camera Angle:\", [\"Close-up\", \"Wide-angle\", \"Overhead\", \"First-person view\", \"Isometric\"])\n",
    "    mood = st.selectbox(\"Mood & Emotion:\", [\"Mysterious\", \"Dreamy\", \"Futuristic\", \"Cozy\", \"Surreal\", \"Hyper-realistic\"])\n",
    "    color_scheme = st.selectbox(\"Color Scheme:\", [\"Black & White\", \"Pastel Tones\", \"Cyberpunk\", \"Vivid Colors\", \"Monochrome\"])\n",
    "\n",
    "    if image_subject:\n",
    "        image_prompt = f\"Generate a {image_style} image of {image_subject} with {lighting} lighting, {camera_angle} perspective, evoking a {mood} mood, and using a {color_scheme} color scheme.\"\n",
    "        st.write(\"### Generated Image Prompt:\")\n",
    "        st.code(image_prompt)\n",
    "\n",
    "elif selected_page == \"Text Generation\":\n",
    "    st.title(\"AI-Powered Text Generation\")\n",
    "    text_prompt = st.text_input(\"Enter your prompt for text generation:\")\n",
    "\n",
    "    if st.button(\"Generate Text\"):\n",
    "        with st.spinner(\"Generating text...\"):\n",
    "            inputs = tokenizer(text_prompt, return_tensors=\"pt\").to(model.device)\n",
    "            output = model.generate(**inputs, max_new_tokens=500, temperature=0.7)\n",
    "            result = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            st.markdown(\"### Generated Blog:\")\n",
    "            st.write(result)\n",
    "elif selected_page == \"Image Generation\":\n",
    "    st.title(\"AI-Powered Image Generation\")\n",
    "    image_prompt = st.text_input(\"Enter your prompt for image generation:\")\n",
    "    num_images = st.slider(\"Select number of images to generate\", 1, 5, 1)\n",
    "\n",
    "    if st.button(\"Generate Image(s)\"):\n",
    "        with st.spinner(\"Generating images...\"):\n",
    "            images = [pipe(image_prompt, guidance_scale=7.5, height=768, width=768).images[0] for _ in range(num_images)]\n",
    "            st.session_state.generated_images = images\n",
    "\n",
    "        for idx, image in enumerate(images):\n",
    "            st.image(image, caption=f\"Generated Image {idx + 1}\", use_column_width=True)\n",
    "\n",
    "# Download Button\n",
    "if \"generated_text\" in st.session_state or \"generated_images\" in st.session_state:\n",
    "    st.write(\"### Download Generated Content\")\n",
    "    if st.button(\"Download Word Document\"):\n",
    "        doc = Document()\n",
    "\n",
    "        if \"generated_text\" in st.session_state:\n",
    "            doc.add_heading(\"Generated Text\", level=1)\n",
    "            doc.add_paragraph(st.session_state.generated_text)\n",
    "\n",
    "        if \"generated_images\" in st.session_state:\n",
    "            doc.add_heading(\"Generated Images\", level=1)\n",
    "            for idx, image in enumerate(st.session_state.generated_images):\n",
    "                image_stream = BytesIO()\n",
    "                image.save(image_stream, format=\"PNG\")\n",
    "                image_stream.seek(0)\n",
    "                doc.add_paragraph(f\"Image {idx + 1}:\")\n",
    "                doc.add_picture(image_stream, width=Inches(4))  # Resizing images for better fit\n",
    "\n",
    "        doc_io = BytesIO()\n",
    "        doc.save(doc_io)\n",
    "        doc_io.seek(0)\n",
    "\n",
    "        st.download_button(\n",
    "            label=\"Download Word File\",\n",
    "            data=doc_io,\n",
    "            file_name=\"AI_Generated.docx\",\n",
    "            mime=\"application/vnd.openxmlformats-officedocument.wordprocessingml.document\"\n",
    "        )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGofuZJl5dQh",
    "outputId": "8e45b69c-26f8-4ced-8ae3-0bf5b0032bb4"
   },
   "outputs": [],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "QEqJyQTn7wAG",
    "outputId": "9409251d-2a24-4117-8c1f-406e6b96446c"
   },
   "outputs": [],
   "source": [
    "!streamlit run app.py & npx localtunnel --port 8501\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d3fa6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📝 Text Generation\n",
    "\n",
    "Use LLaMA 2 to generate detailed blog content from structured prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71728334",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🖼️ Image Generation\n",
    "\n",
    "Use Stable Diffusion to create AI-generated visuals based on your prompts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b0931e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 💾 Download Output\n",
    "\n",
    "Download the generated blog content or images to your device.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507f20e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Blog generation using LLaMA 2\n",
    "- Image creation using Stable Diffusion\n",
    "- Export to downloadable formats\n",
    "\n",
    "> Built with ❤️ using Python, Hugging Face, and Colab.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
